#!/usr/bin/env python3
"""
Quick Production Import - Load full dataset via API endpoints
This approach uses the existing API infrastructure to load the complete dataset.
"""

import requests
import json
import os
import time

# Production API
API_BASE = "https://raresift-backend.onrender.com"

def test_connection():
    """Test API connection and environment."""
    print("ğŸ”— Testing production API connection...")
    
    try:
        response = requests.get(f"{API_BASE}/health", timeout=90)
        if response.status_code == 200:
            print("âœ… Production API is healthy")
            return True
        else:
            print(f"âŒ API unhealthy: {response.status_code}")
            return False
    except Exception as e:
        print(f"âŒ Connection failed: {e}")
        return False

def check_database_url():
    """Check if DATABASE_URL is available in environment."""
    db_url = os.getenv('DATABASE_URL')
    if db_url:
        print("âœ… DATABASE_URL environment variable found")
        # Hide password for security
        safe_url = db_url.split('@')[1] if '@' in db_url else 'available'
        print(f"ğŸ”— Database: {safe_url}")
        return True
    else:
        print("âŒ DATABASE_URL not found in environment")
        return False

def load_complete_dataset():
    """Load the complete real dataset (22 videos) via admin endpoint."""
    print("ğŸ“Š Loading complete dataset...")
    
    try:
        # First clear existing data
        print("ğŸ§¹ Clearing existing data...")
        response = requests.post(f"{API_BASE}/api/v1/admin/initialize-database", timeout=60)
        if response.status_code == 200:
            print("âœ… Database cleared successfully")
        else:
            print(f"âš ï¸  Database clear returned: {response.status_code}")
        
        time.sleep(2)  # Brief pause
        
        # Load the real data
        print("ğŸ“¼ Loading real video data...")
        response = requests.post(f"{API_BASE}/api/v1/admin/load-real-data", timeout=120)
        
        if response.status_code == 200:
            result = response.json()
            print(f"âœ… {result['message']}")
            return True
        else:
            print(f"âŒ Failed to load data: {response.status_code}")
            try:
                error_detail = response.json()
                print(f"Error: {error_detail}")
            except:
                print(f"Error text: {response.text}")
            return False
            
    except Exception as e:
        print(f"âŒ Exception during data loading: {e}")
        return False

def trigger_full_processing():
    """Trigger processing of all videos to generate embeddings."""
    print("âš™ï¸  Triggering full video processing for embeddings...")
    
    try:
        # This endpoint should process all uploaded videos and generate embeddings
        response = requests.post(f"{API_BASE}/api/v1/admin/process-all-videos", timeout=300)
        
        if response.status_code == 200:
            result = response.json()
            print(f"âœ… Processing triggered: {result['message']}")
            return True
        elif response.status_code == 404:
            print("âš ï¸  Batch processing endpoint not available")
            print("ğŸ’¡ Individual video processing will happen automatically")
            return True
        else:
            print(f"âš ï¸  Processing returned: {response.status_code}")
            return True  # Continue anyway
            
    except Exception as e:
        print(f"âš ï¸  Processing request failed: {e}")
        print("ğŸ’¡ Individual processing should work automatically")
        return True

def verify_final_state():
    """Verify the final state of the production system."""
    print("ğŸ” Verifying final production state...")
    
    try:
        # Check dashboard stats
        response = requests.get(f"{API_BASE}/api/v1/stats/dashboard", timeout=30)
        if response.status_code == 200:
            stats = response.json()
            print(f"ğŸ“Š Final Production Stats:")
            print(f"   Videos: {stats['totalVideos']}")
            print(f"   Frames: {stats['totalFrames']}")  
            print(f"   Searches: {stats['totalSearches']}")
            print(f"   Storage: {stats['storageUsed']}")
            
            # Test search
            print("ğŸ” Testing search functionality...")
            search_response = requests.post(f"{API_BASE}/api/v1/search/text", 
                json={"query": "car driving", "limit": 3}, timeout=30)
            
            if search_response.status_code == 200:
                results = search_response.json()
                print(f"âœ… Search test: {results['total_found']} results found")
                
                if results['total_found'] > 0:
                    print("ğŸ‰ FULL DATASET IMPORT SUCCESSFUL!")
                    return True
                else:
                    print("âš ï¸  Search returns no results - may need more processing time")
                    return True
            else:
                print(f"âŒ Search test failed: {search_response.status_code}")
                return False
        else:
            print(f"âŒ Stats check failed: {response.status_code}")
            return False
            
    except Exception as e:
        print(f"âŒ Verification failed: {e}")
        return False

def main():
    """Main import process."""
    print("=== Quick Production Dataset Import ===")
    print("ğŸ¯ Goal: Load complete RareSift dataset to production")
    print()
    
    # Step 1: Test connections
    if not test_connection():
        print("âŒ Cannot proceed - API connection failed")
        return False
    
    # DATABASE_URL check (optional for API-based approach)
    has_db_url = check_database_url()
    if not has_db_url:
        print("ğŸ’¡ DATABASE_URL not available locally - using API-only approach")
        print("ğŸ“ Note: This will work through your existing API endpoints")
    
    print()
    print("ğŸš€ Starting import process...")
    print()
    
    # Step 2: Load complete dataset
    if not load_complete_dataset():
        print("âŒ Dataset loading failed")
        return False
    
    time.sleep(3)  # Allow database to settle
    
    # Step 3: Trigger processing
    if not trigger_full_processing():
        print("âŒ Processing trigger failed")
        return False
    
    time.sleep(5)  # Allow processing to start
    
    # Step 4: Verify results
    success = verify_final_state()
    
    if success:
        print()
        print("ğŸ‰ PRODUCTION IMPORT COMPLETED!")
        print("ğŸ”— Frontend: https://raresift-frontend-and9rqi6q-raama-srivatsans-projects.vercel.app")
        print("ğŸ”— Backend API: https://raresift-backend.onrender.com")
        print("ğŸ“š API Docs: https://raresift-backend.onrender.com/docs")
        print("ğŸ’¡ Search functionality should now work with full dataset!")
    else:
        print("âŒ Import completed but verification failed")
    
    return success

if __name__ == "__main__":
    main()